{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeNAnuVuRWam",
        "colab_type": "text"
      },
      "source": [
        "# Классификатор на основе модели от Google\n",
        "\n",
        "Модель:\n",
        "*  https://github.com/mmihaltz/word2vec-GoogleNews-vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJZTF_Ef9Up2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from keras.layers.core import Dense, SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "import nltk\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Flatten, Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Activation\n",
        "from keras.models import Model\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import save_model, load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlQXde5O-rQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b6bfb9f-e8a4-4e3c-eb63-0f5f60ebc80a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV5XgC8h_dyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "  regex_tokenizer = RegexpTokenizer('[a-zA-Z]+')\n",
        "  words = regex_tokenizer.tokenize(text.lower())\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  without_stop_words = [w for w in words if w not in stop_words]\n",
        "  return without_stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDtC-P7bGSPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_from_categorical(prediction, intents):\n",
        "  answers = []\n",
        "\n",
        "  for i in range(prediction.shape[0]):\n",
        "    answers.append(intents[prediction[i]])\n",
        "\n",
        "  return answers\n",
        "\n",
        "def transform_to_categorical(intents_for_each, unique_intents):\n",
        "  intents_to_digit = []\n",
        "\n",
        "  for intent in intents_for_each:\n",
        "    intents_to_digit.append(unique_intents.index(intent))\n",
        "\n",
        "  return to_categorical(intents_to_digit, len(unique_intents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM2rfH1e_3v1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e291ec8a-9387-4c8b-d5ed-8235ffc301ca"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAz99kXJR4Dp",
        "colab_type": "text"
      },
      "source": [
        "Загрузка данных и модели от Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li3SEkHG-itF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "eb13df50-c615-4810-ca6d-b7b96bf20fc6"
      },
      "source": [
        "%%time\n",
        "file_csv = pd.read_csv('drive/My Drive/ForGensim/train.csv')\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(\n",
        "    \"drive/My Drive/ForGensim//GoogleNews-vectors-negative300.bin.gz\",\n",
        "    binary=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 46s, sys: 5.28 s, total: 1min 51s\n",
            "Wall time: 1min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1CQGWIark5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(word2vec_model.vocab)\n",
        "EMBED_SIZE = 300\n",
        "NUM_FILTERS = 256\n",
        "NUM_WORDS = 3\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8Y0eHMlABuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = collections.Counter()\n",
        "maxlen = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MnOP_SHR_mt",
        "colab_type": "text"
      },
      "source": [
        "Просмотрели некоторые слова в словаре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXifKhAR2GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "982fb8a7-0666-466a-f38c-61334a8ff4da"
      },
      "source": [
        "from itertools import islice\n",
        "list(islice(word2vec_model.vocab, 15010, 15020))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John_F._Kennedy',\n",
              " 'ideals',\n",
              " 'insane',\n",
              " 'Dow_Jones_Industrial_Average',\n",
              " 'Guillen',\n",
              " 'Established',\n",
              " 'lip',\n",
              " 'SS',\n",
              " 'Drop',\n",
              " 'prominence']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4vczbH-SIXU",
        "colab_type": "text"
      },
      "source": [
        "Работа с набором данных (удаление стоп-слов, получение частотного словаря, максимальной длины)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd3ZWiuQ-lMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_texts = file_csv['text']\n",
        "all_intents = file_csv['intents']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFEKSXya_j_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = np.array(all_texts.apply(lambda x : tokenize(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSWHSEYLAEqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for words in sentences:\n",
        "    if len(words) > maxlen:\n",
        "        maxlen = len(words)\n",
        "    for word in words:\n",
        "        counter[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4SNrf3SZOL",
        "colab_type": "text"
      },
      "source": [
        "Подготовка данных для обучения на основе модели от Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YODCtwqDZi0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_sz = len(counter) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFjk9oMXYkIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-TuZBPAYpP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs =  tokenizer.texts_to_sequences(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ge_79PEnAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ys = transform_to_categorical(all_intents, all_intents.unique().tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uTtCqrEqtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pad_sequences(xs, maxlen=maxlen)\n",
        "Y = ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5DOYq_kGnhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f25a6fb2-0be7-44de-aaf8-4fe496c83c4b"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = \\\n",
        "    train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7961, 22) (3413, 22) (7961, 5) (3413, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnpXJ8CISiO1",
        "colab_type": "text"
      },
      "source": [
        "Создание keras модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcySL4kKGsJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_weights = np.zeros((vocab_sz, EMBED_SIZE))\n",
        "for word, index in word2index.items():\n",
        "    try:\n",
        "        embedding_weights[index, :] = word2vec_model[word]\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1J1QtuyLCWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COUNT_CLASSES = all_intents.unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pst81ComG1mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_sz, EMBED_SIZE, input_length=maxlen,\n",
        "                    weights=[embedding_weights],\n",
        "                    trainable=True))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS,\n",
        "                 activation=\"relu\"))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(COUNT_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhnw1PA-HAPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "08aa8de8-0e6b-4f5e-bcdb-95b51203a31f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 22, 300)           2773500   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 22, 300)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 20, 256)           230656    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 3,005,441\n",
            "Trainable params: 3,005,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je-G1A9cSnVo",
        "colab_type": "text"
      },
      "source": [
        "Обучение keras модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC87gvzDG85-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "fc308ece-5c3a-4af7-dca7-36b38323cd77"
      },
      "source": [
        "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=[ModelCheckpoint('drive/My Drive/ForGensim/google_keras_model.h5', save_best_only = True)],\n",
        "                    validation_data=(Xtest, Ytest))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7961 samples, validate on 3413 samples\n",
            "Epoch 1/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 0.1745 - acc: 0.9691 - val_loss: 0.0322 - val_acc: 0.9941\n",
            "Epoch 2/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 0.0209 - acc: 0.9967 - val_loss: 0.0247 - val_acc: 0.9938\n",
            "Epoch 3/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 0.0095 - acc: 0.9984 - val_loss: 0.0168 - val_acc: 0.9956\n",
            "Epoch 4/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 0.0042 - acc: 0.9996 - val_loss: 0.0152 - val_acc: 0.9962\n",
            "Epoch 5/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 0.0025 - acc: 0.9999 - val_loss: 0.0144 - val_acc: 0.9962\n",
            "Epoch 6/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0144 - val_acc: 0.9959\n",
            "Epoch 7/10\n",
            "7961/7961 [==============================] - 14s 2ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0142 - val_acc: 0.9959\n",
            "Epoch 8/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 8.9033e-04 - acc: 0.9997 - val_loss: 0.0148 - val_acc: 0.9962\n",
            "Epoch 9/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 7.8639e-04 - acc: 0.9999 - val_loss: 0.0146 - val_acc: 0.9953\n",
            "Epoch 10/10\n",
            "7961/7961 [==============================] - 15s 2ms/step - loss: 5.4337e-04 - acc: 0.9999 - val_loss: 0.0151 - val_acc: 0.9953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30raDZQJLxMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "715e78cf-60bb-44be-bf12-46c24dbc3cd3"
      },
      "source": [
        "score = model.evaluate(Xtest, Ytest, verbose=1)\n",
        "print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3413/3413 [==============================] - 1s 242us/step\n",
            "Test score: 0.015, accuracy: 0.995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jhEcApISwUa",
        "colab_type": "text"
      },
      "source": [
        "Модель обучилась с точностью ~99%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPevD7FFS2Oq",
        "colab_type": "text"
      },
      "source": [
        "# Тестирование (проверка работы) классификатора на небольших данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GIF2m69L1Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = ['Add track to my Digster Future Hits', 'what a temperature today in kirov', 'add to playlist my song my melody', \n",
        "        'What is the hottest temperature on earth right now?', 'Find a movie schedule for 12 hours from now', 'play ed sheeran song'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaWql_6WPiJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8a877465-e6cb-40a8-c208-3351ccd1bd21"
      },
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(test)\n",
        "sequences_test"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 21, 576, 617, 111],\n",
              " [572, 147],\n",
              " [2, 3, 18, 193],\n",
              " [572, 1039, 231],\n",
              " [13, 5, 17, 87],\n",
              " [1, 7325, 18]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C4_x2LXMTWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_predict = pad_sequences(sequences_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zRr0QIbMb9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict_classes(X_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAkakZ3KMg_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "68578a0a-bbc8-459c-9662-e34ca32704f9"
      },
      "source": [
        "answers = transform_from_categorical(prediction, all_intents.unique().tolist()) \n",
        "answers"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AddToPlaylist',\n",
              " 'GetWeather',\n",
              " 'AddToPlaylist',\n",
              " 'GetWeather',\n",
              " 'SearchScreeningEvent',\n",
              " 'PlayMusic']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    }
  ]
}