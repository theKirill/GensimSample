{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeNAnuVuRWam",
        "colab_type": "text"
      },
      "source": [
        "# Классификатор на основе модели от Google\n",
        "\n",
        "Модель:\n",
        "*  https://github.com/mmihaltz/word2vec-GoogleNews-vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJZTF_Ef9Up2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from keras.layers.core import Dense, SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "import nltk\n",
        "import numpy as np\n",
        "import codecs\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Flatten, Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Activation\n",
        "from keras.models import Model\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import save_model, load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlQXde5O-rQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "c382dd05-36f4-49a0-d4b2-d7bf7baf48e2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VV5XgC8h_dyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "  regex_tokenizer = RegexpTokenizer('[a-zA-Z]+')\n",
        "  words = regex_tokenizer.tokenize(text.lower())\n",
        "  stop_words = set(stopwords.words(\"english\"))\n",
        "  without_stop_words = [w for w in words if w not in stop_words]\n",
        "  return without_stop_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDtC-P7bGSPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform_from_categorical(prediction, intents):\n",
        "  answers = []\n",
        "\n",
        "  for i in range(prediction.shape[0]):\n",
        "    answers.append(intents[prediction[i]])\n",
        "\n",
        "  return answers\n",
        "\n",
        "def transform_to_categorical(intents_for_each, unique_intents):\n",
        "  intents_to_digit = []\n",
        "\n",
        "  for intent in intents_for_each:\n",
        "    intents_to_digit.append(unique_intents.index(intent))\n",
        "\n",
        "  return to_categorical(intents_to_digit, len(unique_intents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM2rfH1e_3v1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9a316130-20c1-40f6-95e7-36c20d9cd29d"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAz99kXJR4Dp",
        "colab_type": "text"
      },
      "source": [
        "Загрузка данных и модели от Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "li3SEkHG-itF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d70be390-59a4-4301-bac2-0341747169c0"
      },
      "source": [
        "file_csv = pd.read_csv('drive/My Drive/ForGensim/train.csv')\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(\n",
        "    \"drive/My Drive/ForGensim//GoogleNews-vectors-negative300.bin.gz\",\n",
        "    binary=True)\n",
        "\n",
        "EMBED_SIZE = 300\n",
        "NUM_FILTERS = 256\n",
        "NUM_WORDS = 3\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8Y0eHMlABuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter = collections.Counter()\n",
        "maxlen = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MnOP_SHR_mt",
        "colab_type": "text"
      },
      "source": [
        "Просмотрели некоторые слова в словаре"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXifKhAR2GU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "51063f9c-00e1-49e2-dc1b-feb6352f03f0"
      },
      "source": [
        "from itertools import islice\n",
        "list(islice(word2vec_model.vocab, 15010, 15020))"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John_F._Kennedy',\n",
              " 'ideals',\n",
              " 'insane',\n",
              " 'Dow_Jones_Industrial_Average',\n",
              " 'Guillen',\n",
              " 'Established',\n",
              " 'lip',\n",
              " 'SS',\n",
              " 'Drop',\n",
              " 'prominence']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4vczbH-SIXU",
        "colab_type": "text"
      },
      "source": [
        "Работа с набором данных (удаление стоп-слов, получение частотного словаря, максимальной длины)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd3ZWiuQ-lMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_texts = file_csv['text']\n",
        "all_intents = file_csv['intents']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFEKSXya_j_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = np.array(all_texts.apply(lambda x : tokenize(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSWHSEYLAEqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for words in sentences:\n",
        "    if len(words) > maxlen:\n",
        "        maxlen = len(words)\n",
        "    for word in words:\n",
        "        counter[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCRRpwFWD5y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2index = collections.defaultdict(int)\n",
        "for wid, word in enumerate(counter.most_common(VOCAB_SIZE)):\n",
        "    word2index[word[0]] = wid + 1\n",
        "vocab_sz = len(word2index) + 1\n",
        "index2word = {v: k for k, v in word2index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4SNrf3SZOL",
        "colab_type": "text"
      },
      "source": [
        "Подготовка данных для обучения на основе модели от Google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nckGZsdkD97j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs, ys = [], []\n",
        "for i in range(0, len(sentences)):\n",
        "  wids = [word2index[word] for word in sentences[i]]\n",
        "  xs.append(wids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ge_79PEnAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ys = transform_to_categorical(all_intents, all_intents.unique().tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uTtCqrEqtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pad_sequences(xs, maxlen=maxlen)\n",
        "Y = ys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5DOYq_kGnhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46fa6726-0b8e-48e5-ba74-d17796a33da1"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = \\\n",
        "    train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "print(Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7961, 22) (3413, 22) (7961, 5) (3413, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnpXJ8CISiO1",
        "colab_type": "text"
      },
      "source": [
        "Создание keras модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcySL4kKGsJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_weights = np.zeros((vocab_sz, EMBED_SIZE))\n",
        "for word, index in word2index.items():\n",
        "    try:\n",
        "        embedding_weights[index, :] = word2vec_model[word]\n",
        "    except KeyError:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1J1QtuyLCWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COUNT_CLASSES = all_intents.unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pst81ComG1mY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_sz, EMBED_SIZE, input_length=maxlen,\n",
        "                    weights=[embedding_weights],\n",
        "                    trainable=True))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(Conv1D(filters=NUM_FILTERS, kernel_size=NUM_WORDS,\n",
        "                 activation=\"relu\"))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(COUNT_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhnw1PA-HAPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "4dd3e3e3-d9a6-47ec-93e1-f6fd3d51f770"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 22, 300)           1500300   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_5 (Spatial (None, 22, 300)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 20, 256)           230656    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 1285      \n",
            "=================================================================\n",
            "Total params: 1,732,241\n",
            "Trainable params: 1,732,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je-G1A9cSnVo",
        "colab_type": "text"
      },
      "source": [
        "Обучение keras модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC87gvzDG85-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "9b7ff8bd-66b8-45db-d640-093a6994e577"
      },
      "source": [
        "history = model.fit(Xtrain, Ytrain, batch_size=BATCH_SIZE,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    callbacks=[ModelCheckpoint('drive/My Drive/ForGensim/google_keras_model.h5', save_best_only = True)],\n",
        "                    validation_data=(Xtest, Ytest))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 7961 samples, validate on 3413 samples\n",
            "Epoch 1/10\n",
            "7961/7961 [==============================] - 14s 2ms/step - loss: 0.2016 - acc: 0.9567 - val_loss: 0.0375 - val_acc: 0.9927\n",
            "Epoch 2/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0258 - acc: 0.9952 - val_loss: 0.0230 - val_acc: 0.9950\n",
            "Epoch 3/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0116 - acc: 0.9985 - val_loss: 0.0170 - val_acc: 0.9968\n",
            "Epoch 4/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0141 - val_acc: 0.9965\n",
            "Epoch 5/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0135 - val_acc: 0.9971\n",
            "Epoch 6/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0133 - val_acc: 0.9974\n",
            "Epoch 7/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0126 - val_acc: 0.9974\n",
            "Epoch 8/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0128 - val_acc: 0.9974\n",
            "Epoch 9/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0137 - val_acc: 0.9974\n",
            "Epoch 10/10\n",
            "7961/7961 [==============================] - 13s 2ms/step - loss: 9.8507e-04 - acc: 0.9999 - val_loss: 0.0126 - val_acc: 0.9974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30raDZQJLxMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "89db9dd2-81b0-4db9-ac1c-5d0a3905c8a8"
      },
      "source": [
        "score = model.evaluate(Xtest, Ytest, verbose=1)\n",
        "print(\"Test score: {:.3f}, accuracy: {:.3f}\".format(score[0], score[1]))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3413/3413 [==============================] - 1s 245us/step\n",
            "Test score: 0.013, accuracy: 0.997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jhEcApISwUa",
        "colab_type": "text"
      },
      "source": [
        "Модель обучилась с точностью ~99%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPevD7FFS2Oq",
        "colab_type": "text"
      },
      "source": [
        "# Тестирование (проверка работы) классификатора на небольших данных"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GIF2m69L1Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = ['Add track to my Digster Future Hits', 'what a temperature today in kirov', 'add to playlist my song my melody', \n",
        "        'What is the hottest temperature on earth right now?', 'Find a movie schedule for 12 hours from now'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3hynV0HPrVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaWql_6WPiJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ab8486a0-71cf-4c0c-ce8d-ed7d1d5f6ea9"
      },
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(test)\n",
        "sequences_test"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 21, 576, 617, 111],\n",
              " [572, 147],\n",
              " [2, 3, 18, 193],\n",
              " [572, 1039, 231],\n",
              " [13, 5, 17, 87]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C4_x2LXMTWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_predict = pad_sequences(sequences_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zRr0QIbMb9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = model.predict_classes(X_predict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAkakZ3KMg_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "197b854b-3fcd-440d-9fc7-fb5e83b84f04"
      },
      "source": [
        "answers = transform_from_categorical(prediction, all_intents.unique().tolist()) \n",
        "answers"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AddToPlaylist',\n",
              " 'GetWeather',\n",
              " 'AddToPlaylist',\n",
              " 'GetWeather',\n",
              " 'SearchScreeningEvent']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    }
  ]
}